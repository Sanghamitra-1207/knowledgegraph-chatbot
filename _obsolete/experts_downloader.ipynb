{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699aea8c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting faker\n",
      "  Using cached faker-37.3.0-py3-none-any.whl (1.9 MB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl (201 kB)\n",
      "Collecting tzdata\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: urllib3, tzdata, idna, charset-normalizer, certifi, requests, faker\n",
      "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.2 faker-37.3.0 idna-3.10 requests-2.32.3 tzdata-2025.2 urllib3-2.4.0\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe52935",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "api_key = \"\"\n",
    "api_id = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c27796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs: 551\n"
     ]
    }
   ],
   "source": [
    "## GET OUTPUTS\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Params\n",
    "number_of_outputs = 1000\n",
    "\n",
    "params = {\"Limit\": number_of_outputs}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-DWS-OCS-Key\": api_key,\n",
    "    \"X-DWS-OCS-AppId\": api_id,\n",
    "}\n",
    "outputs_response = requests.get(\n",
    "    \"https://dws.roche.com/DigitalWorkspace_OCS_API/rest/Sinequa/OCS_Output?\",\n",
    "    params=params,\n",
    "    headers=headers,\n",
    ")\n",
    "outputs_data = outputs_response.json()[\"RecordList\"]\n",
    "print(f\"Number of outputs: {len(outputs_data)}\")\n",
    "\n",
    "# Serializing json\n",
    "outputs_json_object = json.dumps(outputs_data, indent=4)\n",
    "\n",
    "with open(\"outputs.json\", \"w\") as outfile:\n",
    "    outfile.write(outputs_json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215a59b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of works: 2794\n"
     ]
    }
   ],
   "source": [
    "## GET WORKS\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Params\n",
    "number_of_works = 3000\n",
    "\n",
    "params = {\"Limit\": number_of_works}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-DWS-OCS-Key\": api_key,\n",
    "    \"X-DWS-OCS-AppId\": api_id,\n",
    "}\n",
    "works_response = requests.get(\n",
    "    \"https://dws.roche.com/DigitalWorkspace_OCS_API/rest/Sinequa/OCS_Work?\",\n",
    "    params=params,\n",
    "    headers=headers,\n",
    ")\n",
    "works_data = works_response.json()[\"RecordList\"]\n",
    "print(f\"Number of works: {len(works_data)}\")\n",
    "\n",
    "# Serializing json\n",
    "works_json_object = json.dumps(works_data, indent=4)\n",
    "\n",
    "with open(\"works.json\", \"w\") as outfile:\n",
    "    outfile.write(works_json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f275c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE WORKS AND OUTPUTS\n",
    "\n",
    "# Assuming works_data and outputs_data are lists of dicts\n",
    "combined = works_data + outputs_data\n",
    "combined_json_object = json.dumps(combined, indent=4)\n",
    "\n",
    "with open(\"original_data.json\", \"w\") as outfile:\n",
    "    outfile.write(combined_json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "040f1998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique expert IDs: 114\n",
      "Failed to fetch expert profile for ID: 1049157\n",
      "Fetched 113 experts out of processed 3345 outputs and works.\n"
     ]
    }
   ],
   "source": [
    "### Fetching expert IDs from the Digital Workspace Service (DWS) API\n",
    "experts_ids = []\n",
    "experts = []\n",
    "\n",
    "for item in combined:\n",
    "    expert_id = item.get(\"ExpertId\")\n",
    "    if expert_id not in experts_ids:\n",
    "        experts_ids.append(item[\"ExpertId\"])\n",
    "\n",
    "print(f\"Number of unique expert IDs: {len(experts_ids)}\")\n",
    "\n",
    "for expert_id in experts_ids:\n",
    "    params = {\"UserId\": expert_id}\n",
    "    expert_response = requests.get(\n",
    "        \"https://dws.roche.com/DigitalWorkspace_Home_API/rest/Sinequa/GetExpertProfile_GET?\",\n",
    "        params=params,\n",
    "        headers=headers,\n",
    "    )\n",
    "\n",
    "    if (\n",
    "        expert_response.status_code == 200\n",
    "        and len(expert_response.json()[\"RecordList\"]) > 0\n",
    "    ):\n",
    "        experts.append(expert_response.json()[\"RecordList\"][0])\n",
    "    else:\n",
    "        print(f\"Failed to fetch expert profile for ID: {expert_id}\")\n",
    "\n",
    "print(\n",
    "    f\"Fetched {len(experts)} experts out of processed {len(combined)} outputs and works.\"\n",
    ")\n",
    "\n",
    "experts_json_object = json.dumps(experts, indent=4)\n",
    "\n",
    "with open(\"experts.json\", \"w\") as outfile:\n",
    "    outfile.write(experts_json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f2a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faker\n",
    "import json\n",
    "\n",
    "fake = faker.Faker()\n",
    "original_file = \"original_data.json\"\n",
    "expert_file = \"experts.json\"\n",
    "\n",
    "\n",
    "remove_list = [\n",
    "    \"EncodedTitle\",\n",
    "    \"ClickURL\",\n",
    "    \"externalJobs\",\n",
    "    \"Photo\",\n",
    "    \"Content\",\n",
    "    \"internalProjects\",\n",
    "    \"Recomendations\",\n",
    "    \"ActivityLinks\",\n",
    "    \"Username\",\n",
    "]\n",
    "name_list = [\"Title\", \"FirstName\", \"LastName\"]\n",
    "works_list = [\"Owner\"]\n",
    "contact_list = [\"Email\", \"Phone\", \"Mobile\"]\n",
    "\n",
    "\n",
    "def remove_data(processed_record):\n",
    "    for attribute in remove_list:\n",
    "        if attribute in processed_record:\n",
    "            del processed_record[attribute]\n",
    "\n",
    "\n",
    "def anonymize_name(processed_record, list, name, last_name, full_name):\n",
    "    for attribute in list:\n",
    "        if attribute in processed_record:\n",
    "            if \"FirstName\" in attribute:\n",
    "                processed_record[attribute] = processed_record[attribute].replace(\n",
    "                    processed_record[attribute], name\n",
    "                )\n",
    "            elif \"LastName\" in attribute:\n",
    "                processed_record[attribute] = processed_record[attribute].replace(\n",
    "                    processed_record[attribute], last_name\n",
    "                )\n",
    "            else:\n",
    "                processed_record[attribute] = processed_record[attribute].replace(\n",
    "                    processed_record[attribute], full_name\n",
    "                )\n",
    "\n",
    "\n",
    "def anonymize_contacts(processed_record, email, phone, mobile):\n",
    "    for attribute in contact_list:\n",
    "        if attribute in processed_record:\n",
    "            if \"Email\" in attribute:\n",
    "                processed_record[attribute] = processed_record[attribute].replace(\n",
    "                    processed_record[attribute], email\n",
    "                )\n",
    "            elif \"Phone\" in attribute:\n",
    "                processed_record[attribute] = processed_record[attribute].replace(\n",
    "                    processed_record[attribute], phone\n",
    "                )\n",
    "            elif \"Mobile\" in attribute:\n",
    "                processed_record[attribute] = processed_record[attribute].replace(\n",
    "                    processed_record[attribute], mobile\n",
    "                )\n",
    "\n",
    "\n",
    "data = json.load(open(original_file))\n",
    "expert_data = json.load(open(expert_file))\n",
    "for expert_record in expert_data:\n",
    "    fake_name = fake.first_name()\n",
    "    fake_last_name = fake.last_name()\n",
    "    fake_full_name = f\"{fake_name} {fake_last_name}\"\n",
    "    fake_email = f\"{fake_name.lower()}.{fake_last_name.lower()}@roche.com\"\n",
    "    fake_phone = fake.phone_number()\n",
    "    fake_mobile = fake.phone_number()\n",
    "    remove_data(expert_record)\n",
    "    for record in data:\n",
    "        if expert_record[\"Id\"] == record[\"ExpertId\"]:\n",
    "            remove_data(record)\n",
    "            anonymize_name(\n",
    "                record, works_list, fake_name, fake_last_name, fake_full_name\n",
    "            )\n",
    "            anonymize_contacts(record, fake_email, fake_phone, fake_mobile)\n",
    "    anonymize_name(expert_record, name_list, fake_name, fake_last_name, fake_full_name)\n",
    "    anonymize_contacts(expert_record, fake_email, fake_phone, fake_mobile)\n",
    "\n",
    "works_cleaned_json_object = json.dumps(data, indent=4)\n",
    "experts_cleaned_json_object = json.dumps(expert_data, indent=4)\n",
    "with open(\"works_cleaned.json\", \"w\") as outfile:\n",
    "    outfile.write(works_cleaned_json_object)\n",
    "with open(\"experts_cleaned.json\", \"w\") as outfile:\n",
    "    outfile.write(experts_cleaned_json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
